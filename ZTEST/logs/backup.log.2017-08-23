ERROR main youe.data.scala.etl.EtlArithmeticV2 - java.lang.NumberFormatException: For input string: "addr"For input string: "addr"
ERROR main youe.data.scala.etl.EtlArithmeticV2 - Column name or index error, exist columns: name,age,addr_1 , get addr
ERROR Thread-1 org.apache.spark.storage.DiskBlockManager - Exception while deleting local spark dir: C:\Users\Administrator\AppData\Local\Temp\blockmgr-b4566488-0191-4a25-bfc3-a4975cce1cef
java.io.IOException: Failed to delete: C:\Users\Administrator\AppData\Local\Temp\blockmgr-b4566488-0191-4a25-bfc3-a4975cce1cef
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1009)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:168)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:164)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:164)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:159)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1391)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:89)
	at org.apache.spark.SparkContext$$anonfun$org$apache$spark$SparkContext$$_stop$11.apply$mcV$sp(SparkContext.scala:1817)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1290)
	at org.apache.spark.SparkContext.org$apache$spark$SparkContext$$_stop(SparkContext.scala:1816)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1754)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:561)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:215)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1957)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:187)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:187)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:177)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
